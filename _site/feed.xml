<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Notes</title>
    <description>Microbes + Biogeochemistry</description>
    <link>http://slhogle.github.io/</link>
    <atom:link href="http://slhogle.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 13 May 2017 21:59:06 -0400</pubDate>
    <lastBuildDate>Sat, 13 May 2017 21:59:06 -0400</lastBuildDate>
    <generator>Jekyll v3.4.0</generator>
    
      <item>
        <title>Slurm no-number array trick</title>
        <description>&lt;h3 id=&quot;introduction&quot;&gt;INTRODUCTION&lt;/h3&gt;
&lt;p&gt;Slurm can parallelize jobs very nicely if each file has some form of a number in it’s title. For example if your files look like “MYPREFIX0004.txt, MYPREFIX0005.txt, MYPREFIX0006.txt, ect” you could do:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;mylib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;MYPREFIX&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;printf&lt;/span&gt; %04d &lt;span class=&quot;nv&quot;&gt;$SLURM_ARRAY_TASK_ID&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Then just use the $mylib variable in your script and call the script like so:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sbatch --array 5-6 myscript.sbatch&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;which will have the slurm scheduler submit parallel jobs for you to make your jobs run quicker.&lt;/p&gt;

&lt;p&gt;If your file aren’t formatted with a number you can use this workaround.&lt;/p&gt;

&lt;p&gt;Glob the filenames you want to run operations on from whatever directory&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;FILES&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=(&lt;/span&gt;/mypath/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Create var NUMFILES which will be the length of the submitted array job&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;NUMFILES&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${#&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;FILES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[@]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$NUMFILES&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Create a variable in your script that references an array value using $SLURM_ARRAY_TASK_ID as an index&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;basename &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;FILES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SLURM_ARRAY_TASK_ID&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; .tab&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#include file extension if you want to cut that off&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
        <pubDate>Sat, 11 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://slhogle.github.io/2017/slurm-array-job-trick/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2017/slurm-array-job-trick/</guid>
        
        
      </item>
    
      <item>
        <title>Jupyter notebook on remote cluster</title>
        <description>&lt;h3 id=&quot;introduction&quot;&gt;INTRODUCTION&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://jupyter.org/&quot;&gt;Jupyter notebook&lt;/a&gt; is a handy little system for running and documenting your code. You can run it on a remote cluster from your local workstation. Here’s how!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://jupyter.readthedocs.io/en/latest/index.html&quot;&gt;Jupyter docs here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Based off instructions &lt;a href=&quot;https://wikis.uit.tufts.edu/confluence/display/TuftsUITResearchComputing/Jupyter&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;get-an-interactive-terminal&quot;&gt;Get an interactive terminal&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;srun --pty -p sched_mit_NNNNN bash&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Note the node that you are allocated by the slurm scheduler. In this case it is&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;node421&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;start-jupyter-notebook-on-your-node&quot;&gt;Start Jupyter notebook on your node&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;jupyter notebook --no-browser --port&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;8888&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;open-ssh-conncetion-to-cluster-and-node421&quot;&gt;Open ssh conncetion to cluster and node421&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ssh -t -t myname@eofe4.mit.edu -L 8888:localhost:8888 ssh node421 -L 8888:localhost:8888&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;tunnel-from-local-machine-to-jupyter-notebook&quot;&gt;Tunnel from local machine to Jupyter notebook&lt;/h4&gt;
&lt;p&gt;Now direct your browser on your local machine to &lt;a href=&quot;http://localhost:8888/&quot;&gt;http://localhost:8888/&lt;/a&gt;. You should now see the Jupyter notebook view of the filesystem on the cluster.&lt;/p&gt;

&lt;h4 id=&quot;dont-forget-to-close-connection-when-finished&quot;&gt;Don’t forget to close connection when finished&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ctrl-c&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
        <pubDate>Sat, 11 Feb 2017 00:00:00 -0500</pubDate>
        <link>http://slhogle.github.io/2017/remote_jupyter_notebook/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2017/remote_jupyter_notebook/</guid>
        
        
      </item>
    
      <item>
        <title>Installing the bash kernel for Jupyter notebook</title>
        <description>&lt;h3 id=&quot;introduction&quot;&gt;INTRODUCTION&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;http://jupyter.org/&quot;&gt;Jupyter notebook&lt;/a&gt; is a handy little system for running and documenting your code. I use it frequently for my python 2.7 code, but I also write a lot of code in bash. I was using emacs org-mode to write and document my bash scripts, but I recently decided to port them to jupyter notebook. Here’s how to do it!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://jupyter.readthedocs.io/en/latest/index.html&quot;&gt;Jupyter docs here&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;setting-up-python-environment&quot;&gt;Setting up python environment&lt;/h4&gt;
&lt;p&gt;If you haven’t already used it, &lt;a href=&quot;https://www.continuum.io/anaconda-overview&quot;&gt;Anaconda&lt;/a&gt; is a pretty useful system for managing different python installations and environments. Here’s how you install it (python 2.7 version) for OSX:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;wget https://repo.continuum.io/archive/Anaconda2-4.3.0-MacOSX-x86_64.sh
bash Anaconda2-4.3.0-MacOSX-x86_64.sh &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;installing-dependencies&quot;&gt;Installing dependencies&lt;/h4&gt;
&lt;p&gt;The bash kernel for Jupyter notebook requires python 3. Because I do a lot of bioinformatics stuff that relies on python 2.7 I installed that Anaconda version. However, we can easily get python 3.X. Here’s how:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;# Create the environment using Python 3 and add the IPython and Juypter system with notebook support.&lt;/span&gt;
conda create -n py3k &lt;span class=&quot;nv&quot;&gt;python&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3 ipython notebook
&lt;span class=&quot;c&quot;&gt;# now you need to activate the python 3 environment&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;activate py3k&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;installing-the-bash-kernel&quot;&gt;Installing the bash kernel&lt;/h4&gt;
&lt;p&gt;The new bash kernel can be installed using pip (already installed with anaconda)&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;pip install bash_kernel
python -m bash_kernel.install
&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;deactivate py3k&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;running-the-notebook&quot;&gt;Running the notebook&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;# Remember to activate the python 3 env first!&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;activate py3k
&lt;span class=&quot;c&quot;&gt;# start up the notebook server&lt;/span&gt;
jupyter notebook
&lt;span class=&quot;c&quot;&gt;# when you're finished deactivate the python 3 env so we can default to python 2.7&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;deactivate py3k&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now bash should be an available kernel for working in your notebooks. Good to go!&lt;/p&gt;
</description>
        <pubDate>Thu, 19 Jan 2017 00:00:00 -0500</pubDate>
        <link>http://slhogle.github.io/2017/bash_jupyter_notebook/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2017/bash_jupyter_notebook/</guid>
        
        
      </item>
    
      <item>
        <title>Installing Prokka in home folder on a compute cluster</title>
        <description>&lt;h3 id=&quot;introduction&quot;&gt;INTRODUCTION&lt;/h3&gt;
&lt;p&gt;Some colleagues have been asking about installing and using the fabulous &lt;a href=&quot;https://github.com/tseemann/prokka&quot;&gt;Prokka software&lt;/a&gt; on a compute cluster. Without root privledges this can be somewhat tricky if you don’t know where to start. Particularly, on our compute cluster the default Perl version is old, and you don’t have the option to install custom modules due to permissions restrictions. Here’s how you get a working standalone Perl environment that you can update and modify freely and how you install the Prokka perl module dependencies. We’ll be using the glorious &lt;a href=&quot;https://perlbrew.pl/&quot;&gt;Perlbrew&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;setting-up-perl5-environment&quot;&gt;Setting up PERL5 environment&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# change to your home directory&lt;/span&gt;
wget -O - https://install.perlbrew.pl | bash
perlbrew install 5.24.0
cpan App::cpanminus&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;installing-prokka-dependencies&quot;&gt;Installing Prokka dependencies&lt;/h4&gt;
&lt;p&gt;These are the required perl modules for Prokka&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;cpanm Time::Piece XML::Simple Bio::Perl Digest::MD5&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If you are interested in prediciting rRNAs then I would recommend installing the barrnap program&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;wget https://github.com/tseemann/barrnap/archive/0.7.tar.gz
tar zxvf barrnap-0.7.tar.gz&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Finally, add barrnap-0.7/bin to your PATH&lt;/p&gt;

&lt;h4 id=&quot;installing-prokka-itself&quot;&gt;Installing Prokka itself&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git clone https://github.com/tseemann/prokka.git &lt;span class=&quot;c&quot;&gt;# clone the prokka git repository into current directory&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Add prokka-1.1X/bin to your PATH&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;prokka --setupdb&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Good to go!&lt;/p&gt;
</description>
        <pubDate>Thu, 19 Jan 2017 00:00:00 -0500</pubDate>
        <link>http://slhogle.github.io/2017/install_prokka/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2017/install_prokka/</guid>
        
        
      </item>
    
      <item>
        <title>Git and Jekyll Cheatsheet</title>
        <description>&lt;h3 id=&quot;the-short-version&quot;&gt;THE SHORT VERSION&lt;/h3&gt;
&lt;p&gt;Recipe for setting up a repository quick and dirty&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;# my markdown info&quot;&lt;/span&gt; &amp;gt;&amp;gt; README.md
git init
git add README.md
git commit -m &lt;span class=&quot;s2&quot;&gt;&quot;first commit&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;## adding using https protocol&lt;/span&gt;
git remote add origin https://github.com/MYUSERNAME/MY-NEW-REPO.git
&lt;span class=&quot;c&quot;&gt;## RECOMMENDED - or using ssh (after you have added a proper ssh key)&lt;/span&gt;
git remote add origin git@github.com:MYUSERNAME/MY-NEW-REPO
git push -u origin master
&lt;span class=&quot;c&quot;&gt;# …or push an existing repository from the command line&lt;/span&gt;
git remote add origin https://github.com/MYUSERNAME/MY-NEW-REPO.git
git push -u origin master&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;For updating a Jekyll based blog hosted on github pages&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;jekyll serve --watch
&lt;span class=&quot;c&quot;&gt;# take a look at the changes you make live&lt;/span&gt;
jekyll build 
&lt;span class=&quot;c&quot;&gt;# uses jekyll to convert/build html version&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# rendered files located in _site&lt;/span&gt;
git add --all
&lt;span class=&quot;c&quot;&gt;# add all changes in current repo to be staged&lt;/span&gt;
git commit -m &lt;span class=&quot;s2&quot;&gt;&quot;my commit message&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# create a message for the commit&lt;/span&gt;
git push
&lt;span class=&quot;c&quot;&gt;# changes should be live at the github pages site&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Adapted from &lt;a href=&quot;https://services.github.com/on-demand/downloads/github-git-cheat-sheet.pdf&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;configure-tooling&quot;&gt;CONFIGURE TOOLING&lt;/h3&gt;
&lt;p&gt;Configure user information for all local repositories&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git config --global user.name &lt;span class=&quot;s2&quot;&gt;&quot;[name]&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Sets the name you want atached to your commit transactions&lt;/span&gt;
git config --global user.email &lt;span class=&quot;s2&quot;&gt;&quot;[email address]&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Sets the email you want atached to your commit transactions&lt;/span&gt;
git config --global color.ui auto
&lt;span class=&quot;c&quot;&gt;# Enables helpful colorization of command line output&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;create-repositories&quot;&gt;CREATE REPOSITORIES&lt;/h3&gt;
&lt;p&gt;Start a new repository or obtain one from an existing URL&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git init &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;project-name]
&lt;span class=&quot;c&quot;&gt;# Creates a new local repository with the specified name&lt;/span&gt;
git clone &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;url]
&lt;span class=&quot;c&quot;&gt;# Downloads a project and its entire version history&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;make-changes&quot;&gt;MAKE CHANGES&lt;/h3&gt;
&lt;p&gt;Review edits and craft a commit transaction&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git status
&lt;span class=&quot;c&quot;&gt;# Lists all new or modified files to be commited&lt;/span&gt;
git add &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;file]
&lt;span class=&quot;c&quot;&gt;# Snapshots the file in preparation for versioning&lt;/span&gt;
git reset &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;file]
&lt;span class=&quot;c&quot;&gt;# Unstages the fiale, but preserve its contents&lt;/span&gt;
git diff
&lt;span class=&quot;c&quot;&gt;# Shows file differences not yet staged&lt;/span&gt;
git diff --staged
&lt;span class=&quot;c&quot;&gt;# Shows file differences between staging and the last file version&lt;/span&gt;
git commit -m &lt;span class=&quot;s2&quot;&gt;&quot;[descriptive message]&quot;&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# Records file snapshots permanently in version history&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;group-changes&quot;&gt;GROUP CHANGES&lt;/h3&gt;
&lt;p&gt;Name a series of commits and combine completed efforts&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git branch
&lt;span class=&quot;c&quot;&gt;# Lists all local branches in the current repository&lt;/span&gt;
git branch &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;branch-name]
&lt;span class=&quot;c&quot;&gt;# Creates a new branch&lt;/span&gt;
git checkout &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;branch-name]
&lt;span class=&quot;c&quot;&gt;# Switches to the specified branch and updates the working directory&lt;/span&gt;
git merge &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;branch]
&lt;span class=&quot;c&quot;&gt;# Combines the specified branch’s history into the current branch&lt;/span&gt;
git branch -d &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;branch-name]
&lt;span class=&quot;c&quot;&gt;# Deletes the specified branch&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;refactor-filenames&quot;&gt;REFACTOR FILENAMES&lt;/h3&gt;
&lt;p&gt;Relocate and remove versioned files&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git rm &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;file]
&lt;span class=&quot;c&quot;&gt;# Deletes the file from the working directory and stages the deletion&lt;/span&gt;
git rm --cached &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;file]
&lt;span class=&quot;c&quot;&gt;# Removes the file from version control but preserves the file locally&lt;/span&gt;
git mv &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;file-original] &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;file-renamed]
&lt;span class=&quot;c&quot;&gt;# Changes the file name and prepares it for commit&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;suppress-tracking&quot;&gt;SUPPRESS TRACKING&lt;/h3&gt;
&lt;p&gt;Exclude temporary files and paths&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;.log
build/
temp-&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# A text file named .gitignore suppresses accidental versioning of&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# files and paths matching the specified paterns&lt;/span&gt;
git ls-files --other --ignored --exclude-standard
&lt;span class=&quot;c&quot;&gt;# Lists all ignored files in this project&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;save-fragments&quot;&gt;SAVE FRAGMENTS&lt;/h3&gt;
&lt;p&gt;Shelve and restore incomplete changes&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git stash
&lt;span class=&quot;c&quot;&gt;# Temporarily stores all modified tracked files&lt;/span&gt;
git stash list
&lt;span class=&quot;c&quot;&gt;# Lists all stashed changesets&lt;/span&gt;
git stash pop
&lt;span class=&quot;c&quot;&gt;# Restores the most recently stashed files&lt;/span&gt;
git stash drop
&lt;span class=&quot;c&quot;&gt;# Discards the most recently stashed changeset&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;review-history&quot;&gt;REVIEW HISTORY&lt;/h3&gt;
&lt;p&gt;Browse and inspect the evolution of project files&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git log
&lt;span class=&quot;c&quot;&gt;# Lists version history for the current branch&lt;/span&gt;
git log --follow &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;file]
&lt;span class=&quot;c&quot;&gt;# Lists version history for a file, including renames&lt;/span&gt;
git diff &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;first-branch]...[second-branch]
&lt;span class=&quot;c&quot;&gt;# Shows content differences between two branches&lt;/span&gt;
git show &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;commit]
&lt;span class=&quot;c&quot;&gt;# Outputs metadata and content changes of the specified commit&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;redo-commits&quot;&gt;REDO COMMITS&lt;/h3&gt;
&lt;p&gt;Erase mistakes and craft replacement history&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git reset &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;commit]
&lt;span class=&quot;c&quot;&gt;# Undoes all commits afer [commit], preserving changes locally&lt;/span&gt;
git reset --hard &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;commit]
&lt;span class=&quot;c&quot;&gt;# Discards all history and changes back to the specified commit&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;synchronize-changes&quot;&gt;SYNCHRONIZE CHANGES&lt;/h3&gt;
&lt;p&gt;Register a repository bookmark and exchange version history&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git fetch &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bookmark]
&lt;span class=&quot;c&quot;&gt;# Downloads all history from the repository bookmark&lt;/span&gt;
git merge &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;bookmark]/[branch]
&lt;span class=&quot;c&quot;&gt;# Combines bookmark’s branch into current local branch&lt;/span&gt;
git push &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;branch]
&lt;span class=&quot;c&quot;&gt;# Uploads all local branch commits to GitHub&lt;/span&gt;
git pull
&lt;span class=&quot;c&quot;&gt;# Downloads bookmark history and incorporates changes&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Mon, 09 Jan 2017 00:00:00 -0500</pubDate>
        <link>http://slhogle.github.io/2017/gitjekyll-cheatsheet/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2017/gitjekyll-cheatsheet/</guid>
        
        
      </item>
    
      <item>
        <title>Slurm Cheatsheet</title>
        <description>&lt;ul&gt;
  &lt;li&gt;General SLURM documentation found &lt;a href=&quot;https://slurm.schedmd.com/&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;SLURM &lt;a href=&quot;https://slurm.schedmd.com/tutorials.html&quot;&gt;tutorials&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;SLURM tools &lt;a href=&quot;https://www.youtube.com/watch?v=U42qlYkzP9k&amp;amp;feature=player_embedded&quot;&gt;youtube video&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;SLURM &lt;a href=&quot;https://rc.fas.harvard.edu/resources/running-jobs/&quot;&gt;tutorial&lt;/a&gt; @ Harvard&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;submitting-and-cancelling-slurm-jobs&quot;&gt;Submitting and cancelling SLURM jobs&lt;/h3&gt;
&lt;p&gt;Submit a job script called my_script.sh requesting&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;5GB RAM per cpu&lt;/li&gt;
  &lt;li&gt;20 CPUs on a single node&lt;/li&gt;
  &lt;li&gt;use the scheduler queue $MYQUEUE&lt;/li&gt;
  &lt;li&gt;use the job name $MYJOB_NAME&lt;/li&gt;
  &lt;li&gt;provide a time ceiling of 3 HRs&lt;/li&gt;
  &lt;li&gt;write STDOUT to file $MYLOG.log&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sbatch --mem-per-cpu 5GB -c 20 -p &lt;span class=&quot;nv&quot;&gt;$MYQUEUE&lt;/span&gt; -J &lt;span class=&quot;nv&quot;&gt;$MYJOB_NAME&lt;/span&gt; -t 0-3:00:00 -o &lt;span class=&quot;nv&quot;&gt;$MYLOG&lt;/span&gt;.log my_script.sh

&lt;span class=&quot;c&quot;&gt;# Cancel a task with the related JOB_ID&lt;/span&gt;
scancel &lt;span class=&quot;nv&quot;&gt;$MYJOB_ID&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Submit an interactive job&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2GB RAM per cpu&lt;/li&gt;
  &lt;li&gt;4 CPUs on a single node&lt;/li&gt;
  &lt;li&gt;use the scheduler queue $MYQUEUE&lt;/li&gt;
  &lt;li&gt;provide a time ceiling of 1 HR&lt;/li&gt;
  &lt;li&gt;execute task zero in pseudo terminal mode. The option “pty” is important because it allows an interactive terminal mode. Without “pty” every command issued would be run 4 times (-c 4)&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;srun --mem-per-cpu 2GB -c 4 -p &lt;span class=&quot;nv&quot;&gt;$MYQUEUE&lt;/span&gt; -t 0-01:00:00 --pty /bin/bash

&lt;span class=&quot;c&quot;&gt;# Use srun for any long jobs, even cp or rsync&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# DONT USE THE LOGIN NODE&lt;/span&gt;
srun -p &lt;span class=&quot;nv&quot;&gt;$MYQUEUE&lt;/span&gt; cp my_file my_new_file&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;jobs-can-be-submitted-by-passing-all-slurm-parameters-through-bash-script&quot;&gt;Jobs can be submitted by passing all SLURM parameters through bash script&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/usr/bin/env bash&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH --mem-per-cpu 5GB&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH -c 20&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH -p $MYQUEUE&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH -J $MYJOB&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH -t 0-3:00:00&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH -o $MYLOG.log my_script.sh&lt;/span&gt;

raxmlHPC-PTHREADS-AVX -T 20 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
-m GTRGAMMA &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
-p 82748 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
&lt;span class=&quot;gp&quot;&gt;-# &lt;/span&gt;20 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
-s &lt;span class=&quot;nv&quot;&gt;$MY_PHYLIP_FILE&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
-n &lt;span class=&quot;nv&quot;&gt;$MY_NAME&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
-o &lt;span class=&quot;nv&quot;&gt;$MY_OUTGROUP&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
-w &lt;span class=&quot;nv&quot;&gt;$MY_OUTDIR&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Run the RAxML analysis as&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sbatch my_raxml_script.sh&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;find-information-about-partitions-and-jobs&quot;&gt;Find information about partitions and jobs&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;# Display submitted jobs for a given user&lt;/span&gt;
squeue -u &lt;span class=&quot;nv&quot;&gt;$USER&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;List job information&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The sacct command displays job accounting data stored in the job accounting log file or Slurm database in a variety of forms for your analysis. The sacct command displays information on jobs, job steps, status, and exitcodes by default. For the non-root user, the sacct command limits the display of job accounting data to jobs that were launched with their own user identifier (UID) by default. Data for other users can be displayed with the –allusers, –user, or –uid options.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sacct --format&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;CPUTime,MaxRSS,AveRSS,JobName,Timelimit,Start,Elapsed&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Display available partitions on the cluster&lt;/span&gt;
sinfo

&lt;span class=&quot;c&quot;&gt;# List jobs that ran since Dec 1st 2016&lt;/span&gt;
sacct -S 2016-12-01

&lt;span class=&quot;c&quot;&gt;# Get help about sacct command&lt;/span&gt;
sacct --helpformat&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Sun, 04 Dec 2016 00:00:00 -0500</pubDate>
        <link>http://slhogle.github.io/2016/slurm-cheatsheet/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2016/slurm-cheatsheet/</guid>
        
        
      </item>
    
      <item>
        <title>GNU Parallel for mutlithreaded tasks</title>
        <description>&lt;p&gt;We’re sequencing a bunch of single cell bacterial genomes, and I had like a 1000 genomes we needed to quickly call ORFs on and annotate. I’m using the excellent &lt;a href=&quot;https://github.com/tseemann/prokka&quot;&gt;Prokka&lt;/a&gt; software, but I wanted to parallelize it with GNU Parallel. I ended up putting together this series of scripts (based off instructions &lt;a href=&quot;https://rcc.uchicago.edu/documentation/_build/html/running-jobs/srun-parallel/index.html#parallel-batch&quot;&gt;here&lt;/a&gt;) to eventually make it work with our SLURM scheduler. If you know a better way to do this lemme know!&lt;/p&gt;

&lt;p&gt;While I’m at it some useful links for GNU Parallel&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.biostars.org/p/63816/&quot;&gt;Quick tutorial on Biostars&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.gnu.org/software/parallel/parallel_tutorial.html&quot;&gt;Official GNU tutorial&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://rcc.uchicago.edu/documentation/_build/html/tutorials/kicp-tutorials/running-jobs.html&quot;&gt;GNU Parallel and SLURM from U Chicago&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://outreach.ino.pm/presentations/2014/03/genomics-wranglers/index.html#/18&quot;&gt;A nice presentation&lt;/a&gt; by Ino de Bruijn&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;prokkahetssh&quot;&gt;prokka.hets.sh&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/usr/bin/env bash&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;odir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'OUTPATH'&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;rawnucl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'SCAFFOLD_LOCATION'&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;qpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;find &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;rawnucl&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; -name &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;.fna&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;

prokka &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
--addgenes &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
--kingdom Bacteria &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
--outdir &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;odir&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;/&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
--genus Marine_Heterotroph &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
--species &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
--locustag &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
--prefix &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
--cpus 20 &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;qpath&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;prokka.hets.sh is the shell script that will be parallelized. The cool thing is that you can run multi-threaded tasks using this techniqe. For example I’m running Prokka using 20 cores per job. GNU Parallel can cleverly handle available resources such that multi-threaded tasks can be parallelized across multiple nodes. More on that below…&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Of note: $1 is arg1:{1} from parallel.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;parallelsh&quot;&gt;parallel.sh&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/usr/bin/env bash&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#SBATCH --time=04:00:00&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH --nodes=10&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH --ntasks-per-node=1&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH --cpus-per-task=20&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH --exclusive&lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;#SBATCH -p MYQUEUE&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;srun&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;srun --exclusive -N1 -n1 -c&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SLURM_CPUS_PER_TASK&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;parallel&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;parallel --delay .2 -j &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SLURM_NNODES&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; --joblog runtask.log --resume -a &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;parallel&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;srun&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; ./&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Call this script as:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sbatch parallel.sh prokka.hets.sh ids.txt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Where prokka.hets.sh is the script above and ids.txt is a file containing ids (1 per line) of the nucleotide scaffolds that Prokka is to annotate. We use srun to execute the script prokka.hets.sh. The -c$SLURM_CPUS_PER_TASK instructs srun to allocate 20 CPUs to each instance of Prokka that runs.  The –exclusive flag does not let Prokka share nodes with other running jobs and -N1 -n1 mandates that the 20 CPUs be dedicate to a single task (-n1) or a single instance of Prokka that is operating on a single node (-N1). These commands ensure that each Prokka task is confined to running on the 20 cpus residing on a single node.&lt;/p&gt;

&lt;p&gt;For the parallel command –delay .2 prevents overloading the controlling node, -j is the number of tasks parallel runs so but instead of $SLURM_NTASKS we want to use $SLURM_NNODES to tell parallel how many jobs to start. –joblog makes parallel create a log of tasks that it has already run and –resume makes parallel use the joblog to resume from where it has left off. The combination of –joblog and –resume allows jobs to be resubmitted if necessary and continue from where they left off. -a ids.txt is an option for parallel that allows it to use ids.txt as input source rather than arguments from the command line passed by ::: which is quite useful if your input doesn’t neatly follow some shell expansion or something…&lt;/p&gt;

&lt;p&gt;We finally run the parallel command and prokka.hets.sh should be able to use the 20 cpus per node that we requested with -c20 through srun.&lt;/p&gt;
</description>
        <pubDate>Sat, 03 Dec 2016 00:00:00 -0500</pubDate>
        <link>http://slhogle.github.io/2016/gnu-parallel/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2016/gnu-parallel/</guid>
        
        
      </item>
    
      <item>
        <title>Bash commands</title>
        <description>&lt;p&gt;Text form can be found at my &lt;a href=&quot;https://github.com/slhogle/scripts&quot;&gt;github&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/usr/bin/env bash&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Makes bioperl index file of GOS CN assembly&lt;/span&gt;
bp_index.pl -dir . -fmt fasta GOS_ass_CN_index /usr/local/depot/projects/GOS/analysis/jgoll-CN_2012_92pct-annotation/metagene_seq.faa

&lt;span class=&quot;c&quot;&gt;# loops through txt file with 1 accession per line and extracts them using bp_fetch.pl&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;accession_number
&lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;bp_fetch net::&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;accession_number&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt; &amp;lt; accessions.list &amp;gt; results.txt

&lt;span class=&quot;c&quot;&gt;# reads an ID file containing scaffold IDs of TRAP SBP, &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# then loops through *all* scaffold IDs with the annotation 'TRAP' &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# and counts the number of occurences each SBP scaffold has in that file. &lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;accession_number
&lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;grep -c &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;accession_number&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; TRAP_CN_total_assembly
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt; &amp;lt; TRAP_SBP_scf_IDs.formatted.list &amp;gt; results.txt

&lt;span class=&quot;c&quot;&gt;#replaces any instance of one or more whitespace &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# characters with a tab (the g is for global)&lt;/span&gt;
sed -r &lt;span class=&quot;s1&quot;&gt;'s/\s+/\t/g'&lt;/span&gt; rest.out &amp;gt; rest1.out

&lt;span class=&quot;c&quot;&gt;#removes one or more whitespace only at the end of each line&lt;/span&gt;
sed -r &lt;span class=&quot;s1&quot;&gt;'s/\s+$//'&lt;/span&gt; 1-3 &amp;gt; 1-3.out

&lt;span class=&quot;c&quot;&gt;#removes one or more whitespace only at the beginning of each line&lt;/span&gt;
sed -r &lt;span class=&quot;s1&quot;&gt;'s/^\s+//'&lt;/span&gt; rest &amp;gt; rest.out

&lt;span class=&quot;c&quot;&gt;#Separate file by multiple delimiters - in this case it is colon and semicolon&lt;/span&gt;
awk -F &lt;span class=&quot;s1&quot;&gt;'[&amp;gt;...]'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{print $2}'&lt;/span&gt; file

&lt;span class=&quot;c&quot;&gt;#Take a uclust output file, separate spaces by tab, &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# select the second column, remove &quot;&amp;gt;&quot; from that column, &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# remove &quot;...&quot; from the column, print output&lt;/span&gt;
sed -r &lt;span class=&quot;s1&quot;&gt;'s/\s+/\t/g'&lt;/span&gt; art | awk -F &lt;span class=&quot;s1&quot;&gt;'[\t]'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'{print $2}'&lt;/span&gt; | sed -r &lt;span class=&quot;s1&quot;&gt;'s/&amp;gt;//'&lt;/span&gt; | sed -r &lt;span class=&quot;s1&quot;&gt;'s/\.\.\.//'&lt;/span&gt; &amp;gt; out

&lt;span class=&quot;c&quot;&gt;#Remove all rows with a . in the 7th column&lt;/span&gt;
awk &lt;span class=&quot;s1&quot;&gt;'$7 == &quot;.&quot; { next } { print }'&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$file&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#Add Cluster_ to begining of each line in file&lt;/span&gt;
sed -r &lt;span class=&quot;s1&quot;&gt;'s/^/Cluster_/'&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;test&lt;/span&gt; &amp;gt; test.new

&lt;span class=&quot;c&quot;&gt;# Rename all files with *_05242016.fna &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# to *.fna&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;f &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;_05242016.fna
&lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;mv -- &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$f&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;%_05242016.fna&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.fna&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Delete all files in a list called &quot;remove_list.txt&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read&lt;/span&gt; -r entry
&lt;span class=&quot;k&quot;&gt;do 
  &lt;/span&gt;rm &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt; &amp;lt; remove_list.txt

&lt;span class=&quot;c&quot;&gt;# count the files in every subdirectory in a directory&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;D &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;/
&lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -n &lt;span class=&quot;nv&quot;&gt;$D&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot; has this many entries &quot;&lt;/span&gt;
  ls &lt;span class=&quot;nv&quot;&gt;$D&lt;/span&gt; | wc -l
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## RENAME all files in directory &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# from scB241_528N20.contigs.fna to scB241_528N20.fna&lt;/span&gt;
rename .contigs.fna &lt;span class=&quot;s1&quot;&gt;'.fna'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## RENAME all files in directory &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# from scB241_528N20.fna to B241_528N20.fna&lt;/span&gt;
rename scB &lt;span class=&quot;s1&quot;&gt;'B'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## Gets file extensions and prepending paths&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;f &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; /nobackup1/shogle/pro_genomes/sags/simons/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;%.fna&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;##*/&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#split fasta file into files with single fasta entry&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;line
&lt;span class=&quot;k&quot;&gt;do
    if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[[&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;line&lt;/span&gt;:0:1&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'&amp;gt;'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;then
        &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;outfile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;#&amp;gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;.fa
        &lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt; &amp;gt; &lt;span class=&quot;nv&quot;&gt;$outfile&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else
        &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$line&lt;/span&gt; &amp;gt;&amp;gt; &lt;span class=&quot;nv&quot;&gt;$outfile&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;fi
done&lt;/span&gt; &amp;lt; tmp.fasta

&lt;span class=&quot;c&quot;&gt;## find lines that exist in file &quot;all&quot; that don't exist in file &quot;have&quot;&lt;/span&gt;
comm -13 &amp;lt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;sort have&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &amp;lt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;sort all&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &amp;gt; ids_4_phylosift.txt

&lt;span class=&quot;c&quot;&gt;## show differences between file &quot;have&quot; and &quot;all&quot; in &lt;/span&gt;
&lt;span class=&quot;c&quot;&gt;# side by side format and with width of 72 characters&lt;/span&gt;
diff -y -W 72 &amp;lt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;sort have&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &amp;lt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;sort all&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;## parse the ncbi taxonomy tree (nodes.dmp) searching for a (partial) list of ids in file names.txt&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;entry
&lt;span class=&quot;k&quot;&gt;do
  &lt;/span&gt;grep &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;entry&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; names.dmp | gsed &lt;span class=&quot;s1&quot;&gt;'s/\t//g'&lt;/span&gt; | gcut -d &lt;span class=&quot;s2&quot;&gt;&quot;|&quot;&lt;/span&gt; -f1,2 | gsed &lt;span class=&quot;s1&quot;&gt;'s/|/\t/g'&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;done&lt;/span&gt; &amp;lt; names.txt &amp;gt; filtered_pro.txt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Sat, 03 Dec 2016 00:00:00 -0500</pubDate>
        <link>http://slhogle.github.io/2016/bash-notebook/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2016/bash-notebook/</guid>
        
        
      </item>
    
      <item>
        <title>Collecting top hits</title>
        <description>&lt;p&gt;Many times in bioinformatics you’ll have searched many sequences against a database (for example hmmscan versus pfamA). Say you are interested in only retaining the highest scoring PFAM hits for each of your query sequences. Depending on your cutoff score and the number of expected protein domains, each sequence may have gotten hits to multiple different PFAMs. For example, feoB transporters have GTPase-like binding domains, and it is easy to mis-annotate other sequences with GTPase domains as feoB proteins.&lt;/p&gt;

&lt;p&gt;To reduce a hmmscan output file to only the best scoring PFAMs you could use:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;awk &lt;span class=&quot;s1&quot;&gt;'!x[$3]++'&lt;/span&gt; MYOUTFILE.pfam  &amp;gt; MYBESTHITS.pfam&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;and you would get only the lines containing the PFAMs with highest full-sequence score.&lt;/p&gt;

&lt;p&gt;This code takes advantage of the fact that the output of hmmscan is already ordered with the highest scoring domain first for each sequence. In short, after it sees the first unique “query name” entry it removes all subsequent lines that have that “query name” entry then moves on to the next. If the sequences weren’t sorted with highest scoring PFAMs appearing first this wouldn’t give you the top hits - it would just de-duplicate your file. To make this work on other kinds of files you would need to sort them based on whatever value you are interested in.&lt;/p&gt;

&lt;p&gt;For example you could write:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sort -rnk3 FILE | awk &lt;span class=&quot;s1&quot;&gt;'!x[$2]++'&lt;/span&gt; &amp;gt; OUT&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This sorts FILE from highest to lowest (-r) based on column 3 (-k3) and orders it based on string numeric values (-n) then performs awk command on the output.&lt;/p&gt;

&lt;p&gt;I learned this little trick off stackoverflow and it is &lt;a href=&quot;http://stackoverflow.com/questions/10842118/explain-this-duplicate-line-removing-order-retaining-one-line-awk-command&quot;&gt;explained there&lt;/a&gt; much betther than I can do, but I’ll take a crack at it anyways…&lt;/p&gt;

&lt;p&gt;Basically, what it is doing with our hmmscan output is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Read the current line as input&lt;/li&gt;
  &lt;li&gt;Index array x with the entry in the “query name” field. If it doesnt already exist create it. Arrays in awk are associative so they are like dictionaries in python.&lt;/li&gt;
  &lt;li&gt;Increment value of x[$3] but return the prior value, which will be zero if the “query name” entry has not been seen yet. This is called a postfix increment and is seen for example in C programming.&lt;/li&gt;
  &lt;li&gt;Negate the resulting operator so its value is TRUE when x[$3] is zero causing awk to perform the default function which is print the line&lt;/li&gt;
  &lt;li&gt;Actually increment so x[$3] is no longer zero. The next time the same entry in the “query name” field is seen, the value of x[$3] = 1.&lt;/li&gt;
  &lt;li&gt;The operator is FALSE when x[$3] = 1, so awk does nothing. When a new value for $(3) is seen the process starts over.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 23 Apr 2015 00:00:00 -0400</pubDate>
        <link>http://slhogle.github.io/2015/remove-duplicate-lines/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2015/remove-duplicate-lines/</guid>
        
        
        <category>bioinformatics_notebook</category>
        
      </item>
    
      <item>
        <title>Bowtie and Samtools</title>
        <description>&lt;p&gt;A little out of character for me as I usually work on environmental genomics. I’ve been working on RNAseq data from human stem cells subjected to different treatments of WNT signaling proteins. We are interested in looking for differential expression of certain genes under the different treatment conditions. One great tool for doing this is &lt;a href=&quot;http://bowtie-bio.sourceforge.net/index.shtml&quot;&gt;bowtie&lt;/a&gt; or &lt;a href=&quot;http://bowtie-bio.sourceforge.net/bowtie2/index.shtml&quot;&gt;bowtie2&lt;/a&gt;, which is a very fast and efficient short read aligner. In my case I am using bowtie (not bowtie2) to map the mRNA sequences to the human genome (version hg19). There are a variety of reasons to choose between bowtie and bowtie2 that I won’t go into here. By using a series of other tools in the bowtie family, the resulting mapping are compared to one another and we can search for differences between locations on the genome where mRNA sequences mapped.&lt;/p&gt;

&lt;p&gt;Right now I’ll walk you through some commands I’ve used to take a bunch of sequence files and a reference database of the human genome and spit out coordinates of the human genome where these sequences mapped.&lt;/p&gt;

&lt;p&gt;First off, Bowtie needs something called a genome index. You can either build this yourself or there are lots of prebuilt indexes &lt;a href=&quot;http://support.illumina.com/sequencing/sequencing_software/igenome.html&quot;&gt;here&lt;/a&gt;. Say you’re working on a genome that doesn’t have a prebuilt index. You can make one yourself just from the fasta files of that genome. For example…&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;./bowtie-build &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;options]&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &amp;lt;reference_in&amp;gt; &amp;lt;ebwt_base&amp;gt;
./bowtie-build -f chr1.fa,chr2.fa,chr3.fa,chr4.fa,chr5.fa... hg19&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;OK so now you’ve got your Bowtie-formatted genome index. In my case it is called “hg19.” You can map a variety of sequence file types to your genome index and these file types are indicated by different flags. In my case, I have a file of what’s called “raw sequences” this is one sequence per line with no header of any kind per sequence. To tell bowtie what kinds of sequences you need to use different flags: -r is for raw sequences, -f is for old fashioned fasta files, -q is for fastq files. If your sequences are raw or fasta formatted, bowtie gives them a default Phred quality score of 40.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;bowtie -r -n 3 -l 50 -m 1 -S ~/FILEPATH/hg19 ~/FILEPATH/mRNASEQNAME.raw ~/FILEPATH/MYmRNAOUTPUT.sam&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The -r flag tells bowtie to expect raw sequences, the -n flag denotes the maximum number of mismatches permitted in the “seed,” the -l flag denotes the “seed length”; i.e., the number of bases on the high-quality end of the read to which the -n ceiling applies, and the the -m flag tells bowtie to suppress all alignments for a particular read if more than X reportable alignments exist for it. The -S flag tells bowtie to write the output in SAM format. In our case we want bowtie to write out all alignments using a seed length of 50 bases allowing no more than 3 mismatches in those 50 bases, and if a sequence maps to more than one place in the reference genome under those -n and -l conditions to not report any of those alignments. In my experience these are good mapping conditions to start with.&lt;/p&gt;

&lt;p&gt;SAM files are BIG. If you find yourself doing many of these kinds of bowtie analyses you will quickly see that the SAM files start to take up many gigabytes of disk space. A solution to the SAM size issue is to convert the SAM output from bowtie to BAM format. BAM is a binary format that takes up less space than the text content of SAM and can be passed to downstream tools later. Bowtie does not write to BAM format so you need to use SAMtools to do this. An efficient method that I like to use to get BAM format in one step is to pipe the output of bowtie to &lt;a href=&quot;http://samtools.sourceforge.net/&quot;&gt;Samtools&lt;/a&gt; like so:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;bowtie -r -n 3 -l 50 -m 1 -S ~/FILEPATH/hg19 ~/FILEPATH/mRNASEQNAME.raw | samtools view -bSF4 - &amp;gt; ~/FILEPATH/MYmRNAOUTPUT.bam&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The first part of this is the same as above but omitting the output file name. We then use a pipe to send the output to samtools. We use the “view” mode to extract/print all or sub alignments in SAM or BAM format. The flags -bSF4 mean to output in bam format while expecting input to be in SAM format, while also omitting any alignments that have the “4” flag which indicates that the query sequence itself is unmapped to the reference genome. This output format is useful so the downstream analyses don’t get clogged up with unmapped reads.&lt;/p&gt;

&lt;p&gt;Next post I’ll show you how to send some BAM files to the cuffdiff tool to find differences between the two files - ie) differences in gene expression.&lt;/p&gt;
</description>
        <pubDate>Thu, 29 May 2014 00:00:00 -0400</pubDate>
        <link>http://slhogle.github.io/2014/bowtie-and-samtools/</link>
        <guid isPermaLink="true">http://slhogle.github.io/2014/bowtie-and-samtools/</guid>
        
        
        <category>bioinformatics_notebook</category>
        
      </item>
    
  </channel>
</rss>
